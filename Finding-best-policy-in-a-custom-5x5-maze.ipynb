{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy grid (0=up, 1=right, 2=down, 3=left):\n",
      "[[0 3 3 3 2]\n",
      " [0 0 0 0 2]\n",
      " [0 0 0 1 2]\n",
      " [0 0 1 1 2]\n",
      " [0 1 1 1 0]]\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/code/output/output.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f6a15ed295d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/code/output/output.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   3226\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3227\u001b[0m         )\n\u001b[1;32m-> 3228\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             )\n\u001b[0;32m    185\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m             \u001b[1;31m# No explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/code/output/output.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# The model of the maze environment is provided for your reference.\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "ACTION_UP    =  0\n",
    "ACTION_RIGHT =  1\n",
    "ACTION_DOWN  =  2\n",
    "ACTION_LEFT  =  3\n",
    "\n",
    "\n",
    "\n",
    "class GridWorld(object):\n",
    "    def __init__(self,shape=[5,5]):\n",
    "        self.shape = shape\n",
    "\n",
    "\n",
    "        numStates  = shape[0] * shape[1]\n",
    "        numActions = 4\n",
    "        self.numStates = numStates\n",
    "        self.numActions = numActions\n",
    "        \n",
    "        xmax = shape[0]\n",
    "        ymax = shape[1]\n",
    "\n",
    "        grid = np.arange(numStates).reshape(shape)\n",
    "\n",
    "        Model = {}\n",
    "\n",
    "        x_indices = np.arange(xmax)\n",
    "        y_indices = np.arange(ymax)\n",
    "\n",
    "        for x in x_indices:\n",
    "            for y in y_indices:\n",
    "                state = y + x*(xmax)\n",
    "                #print(x,y,state)\n",
    "                Model[state] ={action:[] for action in np.arange(numActions)}\n",
    "\n",
    "                is_terminal_state = lambda state : state == 0 or state == (numStates-1)\n",
    "                reward = 0.0 if is_terminal_state(state) else -1.0\n",
    "\n",
    "\n",
    "                if is_terminal_state(state):\n",
    "                    Model[state][ACTION_UP] = [(1.0,state,reward,True)]\n",
    "                    Model[state][ACTION_RIGHT] = [(1.0,state,reward,True)]\n",
    "                    Model[state][ACTION_DOWN] = [(1.0,state,reward,True)]\n",
    "                    Model[state][ACTION_LEFT] = [(1.0,state,reward,True)]\n",
    "                else:\n",
    "                    next_state = {}\n",
    "                    next_state[ACTION_UP] = state if x == 0 else state - ymax\n",
    "                    next_state[ACTION_RIGHT] = state if y == ymax-1 else state +1\n",
    "                    next_state[ACTION_DOWN] = state if x == xmax-1 else state + ymax\n",
    "                    next_state[ACTION_LEFT] = state if y == 0 else state -1 \n",
    "                    Model[state][ACTION_UP] = [(1.0,next_state[ACTION_UP] ,reward,is_terminal_state(next_state[ACTION_UP]))]\n",
    "                    Model[state][ACTION_RIGHT] = [(1.0,next_state[ACTION_RIGHT],reward,is_terminal_state(next_state[ACTION_RIGHT]))]\n",
    "                    Model[state][ACTION_DOWN] = [(1.0,next_state[ACTION_DOWN],reward,is_terminal_state(next_state[ACTION_DOWN]))]\n",
    "                    Model[state][ACTION_LEFT] = [(1.0,next_state[ACTION_LEFT],reward,is_terminal_state(next_state[ACTION_LEFT]))]\n",
    "        self.model = Model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def value_iteration(env, theta=0.0001, discount_factor=1.0):\n",
    "\n",
    "# Helper function to calculate the value for all actions in a given state    \n",
    "    def compute_value_fn_update(state,value_fn):\n",
    "        value_fn_update = np.zeros(env.numActions)\n",
    "        for action in range(env.numActions):\n",
    "            for prob,next_state,reward,done in env.model[state][action]:\n",
    "                value_fn_update[action] += prob * (reward + discount_factor * value_fn[next_state])\n",
    "                \n",
    "        return value_fn_update \n",
    "    \n",
    "    value_fn = np.zeros(env.numStates)\n",
    "    while True:\n",
    "# Stopping Condition        \n",
    "        delta = 0\n",
    "# Update each state        \n",
    "        for state in range(env.numStates):\n",
    "# Find the best action\n",
    "            action_values = compute_value_fn_update(state, value_fn)\n",
    "            best_action_value = np.max(action_values)\n",
    "# Calculate delta across all states seen so far\n",
    "            delta = max(delta, np.abs(best_action_value - value_fn[state]))\n",
    "# Update the value function\n",
    "            value_fn[state] = best_action_value        \n",
    "# Check if we can stop       \n",
    "        if delta < theta:\n",
    "            break\n",
    "    \n",
    "    # Create a deterministic policy by using the optimal value function\n",
    "    policy = np.zeros([env.numStates, env.numActions])\n",
    "    for state in range(env.numStates):\n",
    "    # Find the best action for this state\n",
    "        A = compute_value_fn_update(state, value_fn)\n",
    "        best_action = np.argmax(A)\n",
    "        # Always take the best action\n",
    "        policy[state, best_action] = 1.0\n",
    "    \n",
    "    return policy, value_fn\n",
    "\n",
    "\n",
    "\n",
    "# Write the code to create a deterministic policy by using the optimal value function. Print the optimal policy.\n",
    "\n",
    "    \n",
    "env = GridWorld()\n",
    "policy, value_fn = value_iteration(env)\n",
    "\n",
    "\n",
    "\n",
    "# Save the final output as described in the sample format given below \n",
    "\n",
    "print(\"Policy grid (0=up, 1=right, 2=down, 3=left):\")\n",
    "print(np.reshape(np.argmax(policy, axis=1), env.shape))\n",
    "print(\"\")\n",
    "\n",
    "data=(np.reshape(np.argmax(policy, axis=1), env.shape))\n",
    "output=pd.DataFrame(data)\n",
    "output.to_csv('/code/output/output.csv', header=False, index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
